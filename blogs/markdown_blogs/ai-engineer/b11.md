# Bölüm 11: Embeddings ve Vektör Veritabanları - Anlamı Matematiğe Dönüştürmek
Yapay zekanın en temel zorluklarından biri, dünyanın karmaşık ve yapılandırılmamış verilerini (metin, resim, ses) alıp, bir makine öğrenmesi modelinin işleyebileceği bir formata sokmaktır. Bir bilgisayar "kedi" kelimesinin ne anlama geldiğini veya bir resmin "hüzünlü" olup olmadığını içgüdüsel olarak bilmez.

İşte bu noktada **Embeddings (Gömülüler)** devreye girer.

## 1. Embeddings: Anlamın Geometrisi
**Embedding nedir?** En basit tanımıyla, bir metin parçasının, bir görselin veya bir sesin anlamsal özünü temsil eden yoğun, sayısal bir **vektördür** (bir dizi sayı).

Bu vektörlerin sihirli özelliği şudur: **Anlamsal yakınlık, geometrik yakınlığa dönüşür.**

Bu ne demek? "Kral" ve "Kraliçe" kelimeleri, bu çok boyutlu vektör uzayında birbirine çok yakın konumlarda yer alır. "Masa" kelimesi ise onlardan çok uzakta olacaktır. Hatta daha da ileri giderek, `"Kral" - "Erkek" + "Kadın"` vektör işleminin sonucu, "Kraliçe" vektörüne çok yakın bir noktayı işaret edecektir.

Bu "anlam haritalarını" biz oluşturmayız; onları `Sentence-BERT`, `CLIP` (görsel ve metin için) veya OpenAI'nin `text-embedding-ada-002` gibi ön-eğitimli modeller oluşturur. Bu modeller, devasa veri setleri üzerinde eğitilirken, bu anlamsal **temsilleri (representations)** öğrenmeyi bir yan ürün olarak üretirler.

## 2. Neden Bu Kadar Güçlüler? Vektörel Uygulamalar
Bu anlamsal haritayı bir kez oluşturduğumuzda, daha önce imkansız olan birçok şeyi yapabiliriz:

* **Anlamsal Arama (Semantic Search):** Bu, geleneksel anahtar kelime (keyword) aramasının tam zıddıdır. Anahtar kelime araması (eski arama motorları gibi), sizin "araba" kelimesini aramanıza bakar. Anlamsal arama ise "araba" kelimesinin **niyetini** arar. Kullanıcının sorgusunu bir vektöre dönüştürür ve veritabanındaki (yine vektöre dönüştürülmüş) belgelere bakar. Kullanıcı "dört tekerlekli taşıt" diye aratsa bile, bu sorgunun vektörü "otomobil" veya "araba" kelimelerini içeren belgelerin vektörlerine yakın olacağı için doğru sonuçları getirir.
* **Veri Sınıflandırma ve Kümeleme:** Vektör uzayında, benzer veriler doğal olarak bir araya toplanır (kümelenir). Bu sayede, "olumlu müşteri yorumları" bir bölgede, "olumsuz yorumlar" ise başka bir bölgede kümelenir. Yeni bir yorum geldiğinde, onun vektörünün hangi kümeye düştüğüne bakarak kolayca sınıflandırabiliriz.
* **Anomali Tespiti (Anomaly Detection):** Bu kümeleme mantığının tersidir. Eğer tüm "normal" ağ trafiğinizin vektörleri uzayın belli bir bölgesinde yoğunlaşmışsa, bu kümenin çok dışında, tek başına duran bir veri noktası (vektör) muhtemelen bir anomali, bir dolandırıcılık girişimi veya bir sistem hatasıdır.
* **Tavsiye Sistemleri (Recommendation Systems):** Kullanıcıların ve ürünlerin vektörlerini oluşturabilirsiniz. "Bu ürünü beğenenler, şunları da beğendi" demek, "Bu ürünün vektörüne yakın olan diğer ürün vektörlerini bul" demenin bir yoludur. Aynı şekilde, bir kullanıcının beğendiği ürünlerin ortalama vektörüne benzer ürünler önerilebilir.

## 3. Mühendislik Problemi: Milyarlarca Vektör Arasında Aramak
Embeddings harikadır, ancak bir mühendislik sorununu da beraberinde getirirler. Elimizde milyonlarca (veya milyarlarca) vektör var. Yeni bir sorgu vektörü geldiğinde, ona en yakın 10 vektörü nasıl bulacağız?

* **Naif (ve yavaş) yöntem:** Sorgu vektörünü alır, veritabanındaki diğer her bir vektörle (milyonlarca kez) aradaki mesafeyi (genellikle kosinüs benzerliği) tek tek hesaplar ve en yakın olanları sıralarız.
* Bu, `O(N)` karmaşıklığındadır ve küçük veri setleri dışında tamamen kullanışsızdır. Bir arama saniyeler sürer.

## 4. Çözüm: Vektör Veritabanları (Vector Databases)
İşte **Vektör Veritabanları** (`Pinecone`, `Weaviate`, `Milvus`, `ChromaDB` vb.) bu sorunu çözmek için tasarlanmıştır. Geleneksel veritabanları (SQL) tam eşleşmeler için optimize edilmiştir. Vektör veritabanları ise **benzerlik** için optimize edilmiştir.

Bunu başarmak için **Yaklaşık En Yakın Komşu (Approximate Nearest Neighbor - ANN)** algoritmaları üzerine kurulu özel indeksleme yapıları kullanırlar.

> **ANN'nin Temel Fikri:** Mükemmel (%100 doğru) en yakın komşuyu bulmak yerine, %99 doğrulukla "neredeyse" en yakın olanları bulmak, ama bunu 1000 kat daha hızlı yapmaktır. Çoğu uygulama için bu "neredeyse mükemmel" sonuç, "mükemmel ama yavaş" sonuçtan çok daha değerlidir.

Bu veritabanları, vektörleri eklediğinizde onları `HNSW` (Hierarchical Navigable Small Worlds) veya `IVF` (Inverted File Index) gibi karmaşık, çok katmanlı veri yapılarında organize eder.

* **HNSW'yi basit bir analojiyle düşünün:** Milyonlarca ev (vektör) arasında bir adresi (sorgu) bulmaya çalışıyorsunuz. HNSW, size önce "ana otoyolu" (üst katman) kullanarak doğru şehre hızlıca gitmenizi sağlar, sonra "yerel yolları" (alt katmanlar) kullanarak hedef evinize (en yakın vektör) çok az sayıda adımda ulaştırır. Tüm evleri tek tek kontrol etmenize gerek kalmaz.

Özetle, **Embeddings** anlamsal bilgiyi matematiğe dönüştüren "temsillerdir". **Vektör Veritabanları** ise bu matematiksel temsilleri depolayan, yöneten ve onlar arasında ışık hızında anlamsal arama yapabilen "optimize edilmiş altyapılardır". Bu ikili, RAG'den modern arama motorlarına kadar her şeyin temelini oluşturur.