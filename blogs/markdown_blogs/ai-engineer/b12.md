# BÃ¶lÃ¼m 12: Embeddings: Anlamsal Temsili Ãœretme YollarÄ± (API vs. AÃ§Ä±k Kaynak)
Bir metnin anlamsal vektÃ¶rÃ¼nÃ¼ (embedding) oluÅŸturmak iÃ§in Ã¶nÃ¼mÃ¼zde iki ana yol bulunur: Bu iÅŸi bir hizmet olarak sunan kapalÄ± bir API kullanmak (Ã¶rn. OpenAI) ya da modeli kendi altyapÄ±mÄ±zda (on-premise) Ã§alÄ±ÅŸtÄ±rarak tam kontrol sahibi olmak (Ã¶rn. aÃ§Ä±k kaynak modeller).

## 1. "Hizmet Olarak" Yol: OpenAI Embeddings API
Bu, en hÄ±zlÄ± ve altyapÄ± maliyeti en dÃ¼ÅŸÃ¼k yoldur. OpenAI, metni anlamsal bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸini, `text-embedding-ada-002` (veya daha yeni modeller) gibi gÃ¼Ã§lÃ¼, genel amaÃ§lÄ± modeller aracÄ±lÄ±ÄŸÄ±yla basit bir API Ã§aÄŸrÄ±sÄ±na indirger.

### NasÄ±l Ã‡alÄ±ÅŸÄ±r:
UygulamanÄ±z, bir metin parÃ§asÄ±nÄ± (cÃ¼mle, paragraf vb.) OpenAI API'sine gÃ¶nderir. API, bu metni analiz eder ve size 1536 boyutlu (modelin tÃ¼rÃ¼ne gÃ¶re deÄŸiÅŸir) bir vektÃ¶r dizisi olarak geri dÃ¶ner.

### KullanÄ±m AlanlarÄ±:
Bu genel amaÃ§lÄ± model, anlamsal arama, veri sÄ±nÄ±flandÄ±rma, kÃ¼meleme ve basit tavsiye sistemleri gibi Ã§ok geniÅŸ bir yelpazedeki gÃ¶revler iÃ§in ÅŸaÅŸÄ±rtÄ±cÄ± derecede iyi performans gÃ¶sterir.

### Stratejik DeÄŸerlendirme (Maliyet):
* **Avantaj:** BaÅŸlangÄ±Ã§ maliyeti sÄ±fÄ±rdÄ±r. AltyapÄ± (GPU, sunucu) yÃ¶netimi, Ã¶lÃ§eklendirme veya model bakÄ±mÄ±yla uÄŸraÅŸmazsÄ±nÄ±z. Bu, tam bir **Ä°ÅŸletme Gideri (OpEx)** modelidir; sadece kullandÄ±ÄŸÄ±nÄ±z token baÅŸÄ±na Ã¶deme yaparsÄ±nÄ±z.
* **Dezavantaj:** YÃ¼ksek hacimli iÅŸlemlerde (milyonlarca dokÃ¼manÄ± indekslerken) maliyet hÄ±zla artabilir. Maliyeti yÃ¶netmek iÃ§in girdileri optimize etmek (gereksiz uzun metinleri kÄ±saltmak) ve istekleri toplu (batch) olarak gÃ¶ndermek Ã¶nemlidir.

### En Ã–nemli KÄ±sÄ±tlama (Gizlilik):
Bu modeli kullanmak, verilerinizin (ne kadar "geÃ§ici" veya "iÅŸlenmez" dense de) anlamsal temsili oluÅŸturulmak Ã¼zere OpenAI sunucularÄ±na gÃ¶nderilmesini gerektirir. YÃ¼ksek dÃ¼zeyde hassas veya regÃ¼le edilmiÅŸ veriler (saÄŸlÄ±k, finans, kiÅŸisel veriler) iÃ§in bu bir engel teÅŸkil edebilir.

## 2. "Tam Kontrol" Yolu: AÃ§Ä±k KaynaklÄ± Embedding Modelleri
Bu yol, "indirmesi Ã¼cretsiz, Ã§alÄ±ÅŸtÄ±rmasÄ± maliyetli" modelidir. Veri gizliliÄŸi, maliyet kontrolÃ¼ veya belirli bir alanda (domain) en yÃ¼ksek performansÄ± elde etme hedefi olduÄŸunda tercih edilir.

### Eski ve Yeni Nesil:
BaÅŸlangÄ±Ã§ta `Word2Vec`, `GloVe` ve `FastText` gibi kelime bazlÄ± embedding modelleri popÃ¼lerdi. Ancak bu modellerin, tÃ¼m cÃ¼mlenin baÄŸlamÄ±nÄ± yakalamak iÃ§in (genellikle kelime vektÃ¶rlerinin ortalamasÄ±nÄ± alarak) kullanÄ±lmasÄ±, anlam kaybÄ±na yol aÃ§Ä±yordu.

Modern yaklaÅŸÄ±m, **Sentence Transformers (CÃ¼mle DÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼leri)** kullanmaktÄ±r.

### Sentence Transformers (S-BERT):
* Bu, tek baÅŸÄ±na bir modelden Ã§ok, bir **mimaridir**. Temel amacÄ±, `BERT` veya `RoBERTa` gibi Transformer modellerini alÄ±p, "semantik olarak anlamlÄ± cÃ¼mle vektÃ¶rleri" Ã¼retecek ÅŸekilde Ã¶zel olarak fine-tune etmektir. `sentence-transformers` kÃ¼tÃ¼phanesi, bu iÅŸlemi inanÄ±lmaz derecede basitleÅŸtirmiÅŸtir.
* **Neden Devrimseldi?** Geleneksel BERT, bir cÃ¼mlenin vektÃ¶rÃ¼nÃ¼ almak iÃ§in (Ã¶rn. `[CLS]` token'Ä±nÄ± veya tÃ¼m token'larÄ±n ortalamasÄ±nÄ±) kullanÄ±ldÄ±ÄŸÄ±nda, anlamsal benzerlik aramasÄ± iÃ§in iyi sonuÃ§lar vermiyordu. S-BERT, modeli "birbirine benzeyen cÃ¼mlelerin vektÃ¶rleri birbirine yakÄ±n olsun" hedefiyle eÄŸitti. Bu, onu anlamsal arama ve benzerlik gÃ¶revleri iÃ§in endÃ¼stri standardÄ± haline getirdi.

### AÃ§Ä±k Kaynak Modellerin Merkezi: Hugging Face Hub
Bu gÃ¼Ã§lÃ¼ aÃ§Ä±k kaynak modelleri bulduÄŸumuz, test ettiÄŸimiz ve indirdiÄŸimiz yer Hugging Face Hub'dÄ±r. Orada, belirli ihtiyaÃ§lara gÃ¶re optimize edilmiÅŸ yÃ¼zlerce model bulabilirsiniz.

* **`all-MiniLM-L6-v2`:** HÄ±z ve verimliliÄŸin kralÄ±dÄ±r. Boyutu Ã§ok kÃ¼Ã§Ã¼ktÃ¼r (`MiniLM`), Ã§ok hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r ve Ã§oÄŸu genel amaÃ§lÄ± gÃ¶rev iÃ§in "yeterince iyi" sonuÃ§lar verir. HÄ±zlÄ± prototipleme veya kaynaklarÄ±n (GPU VRAM) kÄ±sÄ±tlÄ± olduÄŸu ortamlar iÃ§in mÃ¼kemmeldir.
* **`gte-base` / `bge-base-en-v1.5`:** Bunlar, MTEB (Massive Text Embedding Benchmark) liderlik tablolarÄ±nda sÃ¼rekli olarak en Ã¼st sÄ±ralarda yer alan, yeni nesil, yÃ¼ksek performanslÄ± modellerdir. `MiniLM`'den daha bÃ¼yÃ¼ktÃ¼rler ancak Ã§ok daha yÃ¼ksek doÄŸruluk ve daha iyi anlamsal ayrÄ±m gÃ¼cÃ¼ sunarlar.
* **`Qwen2-Embedding` (veya benzeri bÃ¼yÃ¼k modeller):** Ekosistemin ne kadar ilerlediÄŸini gÃ¶steren, milyarlarca parametreye sahip devasa embedding modelleridir. En zorlu ve karmaÅŸÄ±k anlamsal gÃ¶revler iÃ§in tasarlanmÄ±ÅŸlardÄ±r.

### Stratejik Karar: Hangi Yolu SeÃ§meli?
Bu, projenizin gereksinimlerine baÄŸlÄ± bir mÃ¼hendislik kararÄ±dÄ±r:

| Kriter | ğŸš€ OpenAI API (Hizmet) | ğŸ”’ AÃ§Ä±k Kaynak (Yerel/On-Premise) |
| :--- | :--- | :--- |
| **HÄ±z (Pazara Ã‡Ä±kÄ±ÅŸ)** | Ã‡ok YÃ¼ksek. BirkaÃ§ satÄ±r kod ile entegre olur. | DÃ¼ÅŸÃ¼k. AltyapÄ± kurulumu, MLOps ve model seÃ§imi gerektirir. |
| **AltyapÄ± Maliyeti** | SÄ±fÄ±r. (Tamamen OpEx) | YÃ¼ksek. (GPU'lu sunucular gerektirir - CapEx veya YÃ¼ksek OpEx) |
| **KullanÄ±m Maliyeti** | YÃ¼ksek hacimde yÃ¼ksek olabilir. | YÃ¼ksek hacimde dÃ¼ÅŸÃ¼k olabilir (donanÄ±m maliyeti amorti edildikten sonra). |
| **Veri GizliliÄŸi** | DÃ¼ÅŸÃ¼k. Verileriniz Ã¼Ã§Ã¼ncÃ¼ taraf sunucuya gider. | **Tam Kontrol.** Verileriniz sunucunuzdan asla ayrÄ±lmaz. |
| **Performans** | Ã‡ok iyi genel performans. | Ä°yi genel performans. Alan-spesifik (domain-specific) fine-tuning ile mÃ¼kemmel olabilir. |
| **Ã–zelleÅŸtirme** | Yok. Modeli olduÄŸu gibi kullanÄ±rsÄ±nÄ±z. | **SÄ±nÄ±rsÄ±z.** Kendi verinizle fine-tune ederek (Ã¶rn. tÄ±p, hukuk) modeli uzmanlaÅŸtÄ±rabilirsiniz. |

**Ã–zetle:** HÄ±zlÄ± bir prototip mi arÄ±yorsunuz ve veri gizliliÄŸi sorununuz yok mu? `OpenAI API` kullanÄ±n. Hassas verilerle mi Ã§alÄ±ÅŸÄ±yorsunuz, saniyede binlerce isteÄŸi yÃ¶netmeniz mi gerekiyor veya modelin tÄ±p jargonu gibi Ã¶zel bir alanÄ± anlamasÄ± mÄ± gerekiyor? AÃ§Ä±k Kaynak modelini seÃ§in, `sentence-transformers` kÃ¼tÃ¼phanesini aÃ§Ä±n ve Hugging Face Hub'dan gÃ¶revinize en uygun modeli (Ã¶rn. `bge-base`) indirip kendi sunucunuzda Ã§alÄ±ÅŸtÄ±rÄ±n.