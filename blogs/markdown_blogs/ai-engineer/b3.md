## Bölüm 3: Ön-Eğitimli Modeller (Pre-trained Models)
Yapay zeka mühendisliğinde, her projeye sıfırdan başlamak, bir gökdelen inşa etmek için önce çeliği ve betonu icat etmeye çalışmaya benzer. Modern AI geliştirmeyi mümkün kılan devrim niteliğindeki paradigma, ön-eğitimli modellerdir. Bu modeller, AI mühendisliğini "laboratuvar deneyinden" alıp, ölçeklenebilir bir "mühendislik disiplinine" dönüştüren temel yapı taşlarıdır.

### 1. Neden Çalışırlar? Temel Paradigma: Temsil Öğrenme
Bu modellerin gücü, **Transfer Öğrenmesi (Transfer Learning)** adı verilen basit ama güçlü bir fikirden gelir. Bir modeli (örneğin, ResNet veya BERT) devasa bir veri seti (milyonlarca resim, tüm Wikipedia) üzerinde eğittiğinizde, model sadece pikselleri veya kelimeleri ezberlemez. Verinin altında yatan **temsilleri (representations)**, yani desenleri, yapıları ve ilişkileri öğrenir.

-   **Bilgisayarlı Görüde (Computer Vision):** İlk katmanlar kenarları ve köşeleri tanımayı öğrenir. Orta katmanlar bu kenarları birleştirerek dokuları ve basit şekilleri (göz, tekerlek) anlamlandırır. Son katmanlar ise bu şekilleri birleştirerek "kedi", "araba" gibi karmaşık nesneleri tanır.
-   **Doğal Dil İşlemede (NLP):** Model, önce kelimelerin anlamsal ilişkilerini (embedding'ler), sonra gramer kurallarını, ardından "sebep-sonuç" gibi karmaşık ilişkileri ve en sonunda "ironi" veya "duygu" gibi soyut kavramları öğrenir.

Siz bu modeli alıp kendi özel göreviniz (örneğin, "tıbbi görüntülerde tümör tespiti" veya "hukuki belgeleri sınıflandırma") için kullandığınızda, sıfırdan başlamazsınız. Modeliniz, dünyanın veya dilin nasıl çalıştığına dair temel bir anlayışla, adeta tecrübeli bir stajyer gibi başlar.

### 2. Stratejik Kullanım Yöntemleri: Ne Zaman Hangisi?
Ön-eğitimli bir modeli kullanmak, "bir boyuta uyan tek bir çözüm" değildir. Senior bir mühendis, projenin hedeflerine, bütçesine ve veri kısıtlarına göre en doğru stratejiyi seçebilmelidir.

#### a) Özellik Çıkarıcı (Feature Extractor) Olarak Kullanma
-   **Nasıl:** Modelin tüm ağırlıkları **dondurulur** (eğitilemez hale getirilir). Veri, modelden geçirilir ve son (veya bir ara) katmandan çıkan vektörler (embedding'ler) alınır. Bu zenginleştirilmiş özellikler, daha sonra `Scikit-learn` gibi kütüphanelerdeki `Logistic Regression` veya `SVM` gibi daha basit, geleneksel bir ML modeli eğitmek için kullanılır.
-   **Ne Zaman:**
    -   Çok az etiketli veriniz varsa.
    -   Hızlı bir temel model (baseline) oluşturmak istiyorsanız.
    -   Fine-tuning için yeterli donanımınız (GPU VRAM) yoksa.

#### b) İnce Ayar (Fine-Tuning)
-   **Nasıl:** Bu en yaygın senaryodur. Modelin büyük bir kısmı (özellikle alt katmanlar) dondurulur, ancak en üstteki birkaç katman (veya bazen tamamı) "eritilir" (eğitilebilir hale getirilir). Model, kendi etiketli verilerinizle, çok düşük bir **öğrenme oranı (learning rate)** ile yeniden eğitilir. Bu, modelin genel bilgisini korurken, ağırlıklarını sizin özel görevinize "ince ayar" yapmasını sağlar.
-   **Ne Zaman:**
    -   Yeterli miktarda (binlerce veya on binlerce) etiketli veriniz varsa.
    -   Görevde mümkün olan en yüksek doğruluğu hedefliyorsanız.

#### c) Parameter-Efficient Fine-Tuning (PEFT)
-   **Nasıl:** Llama 3 (70B parametre) gibi devasa bir modeli fine-tuning yapmak, tüm ağırlıkları güncellemek muazzam bir GPU belleği gerektirir. PEFT (ve `LoRA` gibi spesifik teknikler), bu soruna dahice bir çözüm sunar. Orijinal modelin milyarlarca parametresinin tamamını dondurur. Bunun yerine, modele "adaptör" adı verilen, eğitilebilir çok küçük (sadece birkaç milyon parametrelik) katmanlar ekler. **Sadece bu adaptörleri eğitirsiniz.**
-   **Ne Zaman:**
    -   Çok büyük dil modelleri (LLM'ler) ile çalışırken maliyetleri (hem eğitim hem de depolama) dramatik şekilde düşürmek için.
    -   Tek bir temel modeli, düzinelerce farklı görev için (her biri kendi küçük adaptör dosyasına sahip) hızlıca uzmanlaştırmak istediğinizde. Bu, modern AI mühendisliğinin temel optimizasyon tekniklerinden biridir.

### 3. Mimari Seçimi: Hangi Model Hangi İşe?
Tüm ön-eğitimli modeller eşit yaratılmamıştır. Göreviniz için yanlış mimariyi seçmek, en baştan başarısızlığa davetiye çıkarmaktır.

-   **Encoder-Only (örn. BERT, RoBERTa, ELECTRA):**
    -   **Mimari:** Metni **çift yönlü** (hem sağdan hem soldan) okuyarak derin bir bağlamsal anlayış geliştirir.
    -   **Görevler (NLU):** Metni **anlamak** üzerine kurulu görevler için idealdir. Metin sınıflandırma, duygu analizi, varlık tanıma (NER), Soru-Cevap (cevap metin içindeyse).

-   **Decoder-Only (örn. GPT serisi, Llama, Mistral, Gemma):**
    -   **Mimari:** Metni **tek yönlü** (soldan sağa) okur ve bir sonraki kelimeyi tahmin etmek üzerine kuruludur (otoregresif).
    -   **Görevler (NLG):** Metin **üretmek** için idealdir. Sohbet botları, kod yazma, yaratıcı metinler oluşturma, özetleme.

-   **Encoder-Decoder (örn. T5, BART):**
    -   **Mimari:** Bir metni "anlamak" için bir encoder ve bu anlayışı kullanarak yeni bir metin "üretmek" için bir decoder kullanır.
    -   **Görevler (Seq2Seq):** Bir diziyi başka bir diziye **dönüştürme** görevleri için en iyisidir. Makine çevirisi (İngilizce -> Türkçe), metin özetleme, veri dönüştürme (JSON -> Doğal Dil).

Senior bir mühendis, "metin üreteceğim" dediğinde bir BERT modeli seçmez; bu mimari farkları bilmek zorundadır.

### 4. Limitasyonlar ve Çözümler
Ön-eğitimli modeller sihirli bir değnek değildir. Kendi teknik borçları ve kısıtlamalarıyla birlikte gelirler.

-   **Sorun: Yanlılık (Bias)**
    -   **Ne:** Modeller, eğitildikleri devasa internet verisindeki tüm ırksal, cinsiyetçi ve toplumsal önyargıları öğrenir ve pekiştirir.
    -   **Çözüm:** Sadece "farkında olmak" yetmez. **Probing** (modelin belirli girdilere nasıl tepki verdiğini sistematik olarak test etme) teknikleri kullanılmalıdır. Fine-tuning aşamasında kullanılacak veri seti, bu yanlılıkları düzeltmek için aktif olarak farklı demografileri temsil edecek şekilde kürate edilmelidir (**data curation**).

-   **Sorun: Alan Uyuşmazlığı (Domain Mismatch)**
    -   **Ne:** "Genel internet" verisiyle eğitilmiş bir model, hukuk, tıp veya finans jargonunu anlamakta başarısız olur.
    -   **Çözüm:** **Domain-Adaptive Pre-training (DAPT)**. Modeli alıp, önce hedef alanınızdaki (örn. tüm tıbbi makaleler) etiketsiz verilerle bir süre daha ön-eğitime tabi tutarsınız. Model, alanın dilini (jargon, terminoloji) öğrendikten sonra spesifik etiketli göreviniz için (örn. "tümör tespiti") fine-tuning yaparsınız. Bu iki aşamalı yaklaşım, performansı ciddi şekilde artırır.

-   **Sorun: "Kara Kutu" (Black Box)**
    -   **Ne:** Modellerin (özellikle büyük olanların) belirli bir kararı neden verdiği anlaşılamaz.
    -   **Çözüm:** `SHAP` veya `LIME` gibi **XAI (Açıklanabilir YZ)** kütüphaneleri, modelin kararlarını yorumlamak için kullanılabilir. Ancak daha önemlisi, Senior mühendis performans ile yorumlanabilirlik arasındaki **trade-off**'u yönetir. Yüksek riskli bir kararda (örn. tıbbi teşhis, kredi onayı), %95 doğruluk veren "kara kutu" bir model yerine, %92 doğruluk veren ama kararları %100 yorumlanabilen daha basit bir modeli (örn. `Logistic Regression`) tercih etmeyi savunabilmelidir.

-   **Sorun: Felaket Unutma (Catastrophic Forgetting)**
    -   **Ne:** Modeli yeni göreviniz için fine-tune ederken, modelin genel dilden öğrendiği faydalı bilgileri "unutması" ve yeni göreve aşırı uzmanlaşmasıdır.
    -   **Çözüm:** Düşük öğrenme oranları (low learning rate) kullanmak, PEFT teknikleri (sadece adaptörleri eğitmek) veya **replay** (yeni veriyle birlikte eski genel veriden küçük bir örneklemle eğitmeye devam etmek) gibi teknikler bu sorunu hafifletir.

-   **Sorun: Çıkarım Maliyeti (Inference Cost)**
    -   **Ne:** Bu modellerin eğitimi bir defalık pahalı bir işlemdir, ancak asıl gizli maliyet **inference (çıkarım)** aşamasındadır. Milyarlarca parametrelik bir modeli 7/24 canlıda, düşük gecikmeyle çalıştırmak, devasa ve pahalı GPU'lar gerektirir.
    -   **Çözüm:** Bu, bir AI Engineer'ın en kritik görevlerindendir. **Quantization** (model ağırlıklarını 32-bit'ten 8-bit'e düşürerek model boyutunu küçültme ve hızı artırma), **Distillation** (büyük "öğretmen" modeli eğitip, ondan öğrendiklerini küçük bir "öğrenci" modele aktarma) ve **Pruning** (modelin gereksiz, kullanılmayan bağlantılarını budama) gibi model sıkıştırma teknikleri, üretim maliyetlerini yönetilebilir kılar.