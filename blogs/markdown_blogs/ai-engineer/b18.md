# BÃ¶lÃ¼m 18: Multimodal AI ğŸ‘ï¸ğŸ”Šâœï¸ - Yapay ZekanÄ±n DÃ¼nyayÄ± Ä°nsanlar Gibi AlgÄ±lamasÄ±
Yapay zeka devriminin ilk aÅŸamasÄ±, metin (NLP) veya gÃ¶rseller (Computer Vision) gibi tek bir veri tÃ¼rÃ¼nde (modalite) uzmanlaÅŸmak Ã¼zerine kuruluydu. Ancak gerÃ§ek dÃ¼nya tek bir modaliteden ibaret deÄŸildir. Biz insanlar dÃ¼nyayÄ±, gÃ¶rdÃ¼klerimizi, duyduklarÄ±mÄ±zÄ± ve okuduklarÄ±mÄ±zÄ± aynÄ± anda iÅŸleyerek, bu verileri birbiriyle iliÅŸkilendirerek anlarÄ±z.

**Multimodal AI**, tam olarak bu felsefeyi makinelere taÅŸÄ±yan yaklaÅŸÄ±mdÄ±r. Metin, gÃ¶rÃ¼ntÃ¼, ses ve videoyu aynÄ± anda iÅŸleyebilen, bunlar arasÄ±nda baÄŸlam kurabilen ve bu entegre anlayÄ±ÅŸa dayalÄ± olarak yanÄ±t Ã¼retebilen sistemleri ifade eder.

Bu yaklaÅŸÄ±m; gÃ¶rsel soru-cevap (VQA), akÄ±llÄ± iÃ§erik moderasyonu, zenginleÅŸtirilmiÅŸ arama motorlarÄ± ve gerÃ§ekten "anlayan" sanal asistanlar gibi devrim niteliÄŸinde uygulamalarÄ±n kapÄ±sÄ±nÄ± aralamÄ±ÅŸtÄ±r.

## Temel Teknik Zorluk: "Dilleri" BirleÅŸtirmek
En bÃ¼yÃ¼k mÃ¼hendislik zorluÄŸu ÅŸuydu: Bir model, anlamsal olarak aynÄ± olan ancak yapÄ±sal olarak tamamen farklÄ± iki ÅŸeyi nasÄ±l iliÅŸkilendirebilir? Yani, bir `kedi.jpg` dosyasÄ±ndaki piksel verisi ile "kedi" kelimesinin metin token'Ä± arasÄ±ndaki baÄŸÄ± nasÄ±l kurar?

### Ã‡Ã¶zÃ¼m: MÃ¼ÅŸterek GÃ¶mme UzayÄ± (Joint Embedding Space)
Bu sorunun Ã§Ã¶zÃ¼mÃ¼, **CLIP (Contrastive Language-Image Pre-Training)** gibi Ã§Ä±ÄŸÄ±r aÃ§an mimarilerle geldi. CLIP'in yaptÄ±ÄŸÄ± ÅŸey ÅŸuydu:

* Bir gÃ¶rÃ¼ntÃ¼ kodlayÄ±cÄ± (Image Encoder - Ã¶rn. Vision Transformer) ve bir metin kodlayÄ±cÄ± (Text Encoder - Ã¶rn. BERT) aldÄ±.
* Bu iki modeli, internetten topladÄ±ÄŸÄ± milyarlarca (resim, metin baÅŸlÄ±ÄŸÄ±) Ã§iftiyle eÄŸitti.
* **Hedef:** "Bir kÃ¶peÄŸin fotoÄŸrafÄ±" metninin vektÃ¶rÃ¼ ile gerÃ§ek bir kÃ¶pek fotoÄŸrafÄ±nÄ±n vektÃ¶rÃ¼nÃ¼, yÃ¼ksek boyutlu bir vektÃ¶r uzayÄ±nda aynÄ± noktaya (veya Ã§ok yakÄ±n bir noktaya) haritalamayÄ± Ã¶ÄŸretmek.

Bu "mÃ¼ÅŸterek uzay" bir kez oluÅŸturulduÄŸunda, farklÄ± modaliteler arasÄ±nda anlamsal "tercÃ¼me" yapmak mÃ¼mkÃ¼n hale geldi. ArtÄ±k "gÃ¶rÃ¼ntÃ¼" ve "metin" aynÄ± dili konuÅŸuyordu.

## Modalitelerin KesiÅŸimi ve UygulamalarÄ±
Bu temel teknoloji, kullanÄ±cÄ±larÄ±n bahsettiÄŸi tÃ¼m o zengin kullanÄ±m alanlarÄ±nÄ± mÃ¼mkÃ¼n kÄ±ldÄ±.

### 1. GÃ¶rÃ¼ntÃ¼ (Image): GÃ¶rmek ve Yaratmak

**GÃ¶rÃ¼ntÃ¼ Anlama (Image Understanding):** Bu, yapay zekanÄ±n "gÃ¶rmesidir". Bir modele (CLIP veya benzeri bir temele sahip) bir gÃ¶rÃ¼ntÃ¼ verdiÄŸinizde, model bu gÃ¶rÃ¼ntÃ¼yÃ¼ anlamsal vektÃ¶r uzayÄ±nda bir noktaya yerleÅŸtirir. ArtÄ±k bu gÃ¶rÃ¼ntÃ¼ hakkÄ±nda metin kullanarak "konuÅŸabilirsiniz".
* **KullanÄ±m AlanÄ±: GÃ¶rsel Soru-Cevap (VQA).** Modele bir resim ve bir soru ("Resimdeki kedi nerede uyuyor?") verirsiniz. Model, resimdeki nesneleri ve metinsel sorguyu aynÄ± uzayda analiz ederek ("Kedi, kanepenin Ã¼zerinde uyuyor.") cevabÄ±nÄ± verir.

**GÃ¶rÃ¼ntÃ¼ Ãœretimi (Image Generation):** Bu, "yaratma" eylemidir. **DALL-E** veya **Stable Diffusion** gibi modeller, bu sÃ¼recin tersini yapar.
* **Teknik AkÄ±ÅŸ:**
    1.  KullanÄ±cÄ± bir metin prompt'u ("Okyanusta yÃ¼zen bir astronot") girer.
    2.  Bu metin, bir metin kodlayÄ±cÄ± (CLIP gibi) kullanÄ±larak anlamsal bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.
    3.  Bu vektÃ¶r, bir **difÃ¼zyon modeline (diffusion model)** "rehber" (guidance) olarak verilir.
    4.  Model, rastgele gÃ¼rÃ¼ltÃ¼den (noise) baÅŸlayarak, her adÄ±mda bu rehber vektÃ¶re anlamsal olarak daha Ã§ok benzeyen bir gÃ¶rÃ¼ntÃ¼ oluÅŸturur.

### 2. Ses (Audio): Duymak ve KonuÅŸmak
Ses, iki ana yÃ¶nde Ã§alÄ±ÅŸÄ±r: girdiyi anlamlandÄ±rmak (STT) ve Ã§Ä±ktÄ±yÄ± seslendirmek (TTS).

* **Speech-to-Text (STT):** Bu, sistemin "kulaÄŸÄ±dÄ±r". **OpenAI Whisper** gibi modeller, konuÅŸulan dili inanÄ±lmaz bir doÄŸrulukla yazÄ±lÄ± metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Multimodal bir sistemde STT, sesli komutlarÄ± alÄ±r ve bunlarÄ±, LLM'in (metin modalitesi) anlayabileceÄŸi bir girdiye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
* **Text-to-Speech (TTS):** Bu, sistemin "sesidir". Modern TTS motorlarÄ± (Ã¶rn. ElevenLabs, OpenAI TTS), metni sadece okumaz. Multimodal bir sistemden gelen (Ã¶rn. "kullanÄ±cÄ± hayal kÄ±rÄ±klÄ±ÄŸÄ±na uÄŸradÄ±") gibi bir duygu verisiyle beslenerek, doÄŸal ve duruma uygun bir ses tonuyla (Ã¼zgÃ¼n, neÅŸeli, ciddi) cevap Ã¼retebilirler.

### 3. Video: ZamanÄ± AlgÄ±lamak
Video, en karmaÅŸÄ±k modalitedir Ã§Ã¼nkÃ¼ sadece gÃ¶rÃ¼ntÃ¼ ve sesten deÄŸil, aynÄ± zamanda **zamandan** da oluÅŸur.

**Video Anlama (Video Understanding):** Multimodal AI, bir videoyu analiz etmek iÃ§in Ã¼Ã§ kanalÄ± birden kullanÄ±r:
* **GÃ¶rsel AkÄ±ÅŸ (Frames):** Her kareyi veya Ã¶nemli kareleri bir Vision Transformer (ViT) ile analiz eder.
* **Ses AkÄ±ÅŸÄ± (Audio):** Arka plan seslerini, mÃ¼ziÄŸi ve konuÅŸmalarÄ± analiz eder (STT burada devreye girer).
* **Zamansal Ä°liÅŸki (Temporal):** Bu iki akÄ±ÅŸta zaman iÃ§inde neler olduÄŸunu (Ã¶rn. Ã¶nce araba gÃ¶rÃ¼ndÃ¼, sonra fren sesi duyuldu) anlamak iÃ§in bir Transformer katmanÄ± daha kullanÄ±r.

**KullanÄ±m AlanlarÄ±:** Bu derin analiz, iÃ§erik moderasyonu (ÅŸiddet iÃ§eren bir sahneyi hem gÃ¶rselden hem de ses efektlerinden tanÄ±ma), video Ã¶zetleme (en kilit sahneleri ve konuÅŸmalarÄ± Ã§Ä±karma) ve video indeksleme (videoda "X kiÅŸisinin Y hakkÄ±nda konuÅŸtuÄŸu anÄ± bul") gibi geliÅŸmiÅŸ uygulamalarÄ± mÃ¼mkÃ¼n kÄ±lar.

## Gelecek: "Yerel" Multimodalite (Natively Multimodal)
Mevcut sistemlerin Ã§oÄŸu, farklÄ± modaliteler iÃ§in farklÄ± uzmanlaÅŸmÄ±ÅŸ modelleri birbirine "yapÄ±ÅŸtÄ±ran" (Ã¶rneÄŸin bir STT modeli + bir LLM + bir TTS modeli) sistemlerdir.

Ancak **Google Gemini** gibi yeni nesil modeller, **"yerel multimodal" (natively multimodal)** bir yaklaÅŸÄ±mla tasarlandÄ±. Bu modeller, en baÅŸÄ±ndan itibaren metin, gÃ¶rÃ¼ntÃ¼ ve ses parÃ§acÄ±klarÄ±nÄ± birbirine karÄ±ÅŸmÄ±ÅŸ (interleaved) tek bir veri setiyle eÄŸitilir.

Bu yaklaÅŸÄ±mda, model iÃ§in bir ses klibi veya bir resim, metin token'Ä±ndan farksÄ±z, sadece baÅŸka bir "token" tÃ¼rÃ¼dÃ¼r. Bu, modelin sadece sÃ¶ylenen kelimeleri deÄŸil, aynÄ± zamanda kelimelerin sÃ¶yleniÅŸ tonunu da (ironi, tereddÃ¼t) doÄŸal bir ÅŸekilde anlamasÄ±na olanak tanÄ±r. Bu, yapay zekanÄ±n dÃ¼nyayÄ± bizim gibi algÄ±lamasÄ±na yÃ¶nelik en Ã¶nemli adÄ±mdÄ±r.