# BÃ¶lÃ¼m 20: Modeli Ãœretimden Stratejiye TaÅŸÄ±mak
Åimdiye kadarki serimizde, modern bir yapay zeka mÃ¼hendisinin alet Ã§antasÄ±ndaki hemen her teknik bileÅŸeni (RAG, Ajanlar, VektÃ¶r VeritabanlarÄ±, Multimodal modeller, GÃ¼venlik protokolleri) birer birer inceledik. Teknik olarak "arabayÄ±" yaptÄ±k; motoru (LLM), tekerlekleri (vektÃ¶r DB) ve direksiyonu (MCP/Ajanlar) baÅŸarÄ±yla birleÅŸtirdik.

Ancak bir **Senior AI Engineer**, sadece arabayÄ± yapan kiÅŸi deÄŸil, aynÄ± zamanda o arabayÄ± yarÄ±ÅŸa sokan, performansÄ±nÄ± Ã¶lÃ§en, motorunu optimize eden (tuning) ve tÃ¼m yarÄ±ÅŸ ekibini (MLOps) yÃ¶neten kiÅŸidir.

Bu bÃ¶lÃ¼mde, tÃ¼m bu parÃ§alarÄ± birleÅŸtiren ve **"teknik uzmanlÄ±ktan" "sistem sahipliÄŸine"** geÃ§iÅŸi saÄŸlayan o kritik Ã¼st seviye konulara odaklanacaÄŸÄ±z.

## 1. DeÄŸerlendirme (Evaluation): "Ä°yi" OlduÄŸunu Nereden Biliyoruz?
Serimizde RAG (BÃ¶lÃ¼m 14) gibi karmaÅŸÄ±k sistemleri nasÄ±l kuracaÄŸÄ±mÄ±zÄ± detaylÄ±ca iÅŸledik. Ama bir deneme (A) yaptÄ±nÄ±z (Ã¶rn. 500'lÃ¼k chunking) ve bir deneme (B) yaptÄ±nÄ±z (Ã¶rn. 1000'lik chunking + Re-ranking). Hangisinin daha iyi olduÄŸunu nasÄ±l anlarsÄ±nÄ±z?

"Bana daha iyi cevap verdi" demek **Ã¶zneldir** ve yeterli deÄŸildir. **Ãœretim seviyesinde (production-grade)** sistemler iÃ§in Ã¶lÃ§Ã¼lebilir, tekrarlanabilir ve objektif metriklere ihtiyacÄ±mÄ±z var.

* **AltÄ±n Veri Seti (Golden Set):** DeÄŸerlendirmenin temeli, bir "test veri seti" (genellikle Soru-Cevap Ã§iftleri) oluÅŸturmaktÄ±r. Bu seti oluÅŸturmak bile baÅŸlÄ± baÅŸÄ±na bir sanattÄ±r.
* **RAG DeÄŸerlendirme Metrikleri:** Sadece "doÄŸruluk" (accuracy) yetmez. RAG pipeline'Ä±mÄ±zÄ± Ã¼Ã§ kritik bileÅŸende Ã¶lÃ§memiz gerekir:

    ### Geri Getirme (Retrieval) Kalitesi:
    * **Context Precision (BaÄŸlam KesinliÄŸi):** Geri getirdiÄŸimiz parÃ§alarÄ±n (context) ne kadarÄ± gerÃ§ekten soruyla ilgiliydi?
    * **Context Recall (BaÄŸlam YakalamasÄ±):** Cevap iÃ§in gereken tÃ¼m bilgi, geri getirdiÄŸimiz parÃ§alarÄ±n iÃ§inde miydi?

    ### Ãœretim (Generation) Kalitesi:
    * **Faithfulness (Sadakat):** Modelin Ã¼rettiÄŸi cevap, sadece saÄŸlanan baÄŸlama ne kadar sadÄ±k? Cevaba halÃ¼sinasyon veya dÄ±ÅŸarÄ±dan bilgi karÄ±ÅŸtÄ±rdÄ± mÄ±?
    * **Answer Relevancy (Cevap Ä°lgiliÄŸi):** Ãœretilen cevap, orijinal soruya ne kadar uygun? (BaÄŸlama sadÄ±k ama sorudan alakasÄ±z cevaplar Ã¼retebilir).

* **DeÄŸerlendirme Framework'leri (AraÃ§lar):** Bu metrikleri manuel olarak hesaplayamayÄ±z. Bu iÅŸi otomatize etmek iÃ§in `RAGAS`, `TruLens`, `DeepEval` gibi Ã¶zel framework'ler kullanÄ±rÄ±z. Bu araÃ§lar, RAG pipeline'Ä±mÄ±zÄ± alÄ±r, altÄ±n veri setimiz Ã¼zerinde Ã§alÄ±ÅŸtÄ±rÄ±r ve bize yukarÄ±daki metrikleri bir skor tablosu olarak sunar.

## 2. Ã‡Ä±karÄ±m Optimizasyonu (Inference Optimization): HÄ±z ve Maliyetin Zirvesi âš¡
Bir Llama 3 veya Mistral modelini `Ollama` (BÃ¶lÃ¼m 9) ile Ã§alÄ±ÅŸtÄ±rmak, geliÅŸtirme (development) iÃ§in harikadÄ±r. Ancak bu modeli saniyede yÃ¼zlerce isteÄŸe (request) hizmet verecek ve bunu en dÃ¼ÅŸÃ¼k maliyetle (yani en ucuz GPU ile) yapacak ÅŸekilde **sunmak (serve)** tamamen farklÄ± bir mÃ¼hendislik problemidir.

Bir Senior Engineer'Ä±n deÄŸeri, modeli "Ã§alÄ±ÅŸtÄ±rmak" deÄŸil, onu **verimli Ã§alÄ±ÅŸtÄ±rmaktÄ±r**.

### Kuantizasyon (Quantization)
Modelin aÄŸÄ±rlÄ±klarÄ±nÄ± `32-bit (FP32)` veya `16-bit (FP16)` yerine `8-bit`, `4-bit` (veya daha dÃ¼ÅŸÃ¼k) tamsayÄ±lar kullanarak temsil etme sanatÄ±dÄ±r. Bu, modelin VRAM (GPU belleÄŸi) ihtiyacÄ±nÄ± dramatik olarak dÃ¼ÅŸÃ¼rÃ¼r ve hÄ±zÄ± artÄ±rÄ±r.
* **Teknikler:** `GGUF`, `GPTQ`, `AWQ` gibi farklÄ± kuantizasyon yÃ¶ntemlerinin hangi senaryolarda (hÄ±z vs. doÄŸruluk kaybÄ±) daha iyi olduÄŸunu bilmek zorundayÄ±z.

### Toplu Ä°ÅŸleme (Batching)
Tek bir GPU'ya aynÄ± anda 1 istek yerine, 16 veya 32 isteÄŸi "toplu" olarak vermek, GPU'nun paralel iÅŸlem gÃ¼cÃ¼nÃ¼ tam olarak kullanmasÄ±nÄ± saÄŸlar ve toplam verimi (throughput) muazzam artÄ±rÄ±r.

### Ã–zel Ã‡Ä±karÄ±m SunucularÄ± (Inference Servers)
Bu optimizasyonlarÄ± manuel yapmak yerine, bu iÅŸ iÃ§in tasarlanmÄ±ÅŸ sunucularÄ± kullanÄ±rÄ±z:
* **NVIDIA Triton Inference Server:** EndÃ¼stri standardÄ±dÄ±r. Birden fazla modeli (farklÄ± framework'lerden) aynÄ± anda sunabilir, dinamik batching yapabilir ve performansÄ± optimize edebilir.
* **vLLM / Hugging Face TGI:** Ã–zellikle LLM'ler iÃ§in tasarlanmÄ±ÅŸtÄ±r. "PagedAttention" gibi geliÅŸmiÅŸ teknikler kullanarak, standart Hugging Face pipeline'Ä±ndan katlarca daha yÃ¼ksek performans ve verim (throughput) saÄŸlarlar.

## 3. MLOps'un OmurgasÄ±: Deneyden Ãœretime ğŸ”„
Serimizde hep **"AI"** kÄ±smÄ±na odaklandÄ±k. Peki ya **"Ops" (Operasyonlar)**? AI projeleri kaotiktir. Bir Senior Engineer, bu kaosu yÃ¶neten araÃ§lara ve sÃ¼reÃ§lere hakim olmalÄ±dÄ±r.

### Deney Takibi (Experiment Tracking)
Bir modeli 10 farklÄ± hiperparametre ile denediniz. Hangisinin en iyi sonucu verdiÄŸini, hangi veri setini kullandÄ±ÄŸÄ±nÄ±zÄ± bir `notdefteri.txt` dosyasÄ±na mÄ± yazacaksÄ±nÄ±z?
* **AraÃ§lar:** `MLflow` veya `Weights & Biases (W&B)` gibi araÃ§lar, her denemenizi (parametreler, metrikler, Ã§Ä±ktÄ± modeller) otomatik olarak kaydeder, karÅŸÄ±laÅŸtÄ±rmanÄ±zÄ± ve tekrarlanabilir (reproducible) olmanÄ±zÄ± saÄŸlar.

### Veri ve Model Versiyonlama (Data & Model Versioning)
Kodu versiyonlamak iÃ§in `Git` kullanÄ±yoruz. Peki ya 50 GB'lÄ±k veri setimizi veya 140 GB'lÄ±k Llama model aÄŸÄ±rlÄ±klarÄ±nÄ±?
* **AraÃ§lar:** `DVC (Data Version Control)` veya `Pachyderm` gibi araÃ§lar, Git benzeri bir mantÄ±kla bÃ¼yÃ¼k veri setlerini ve modelleri versiyonlamamÄ±zÄ± saÄŸlar. BÃ¶ylece "3 ay Ã¶nceki veri setiyle hangi model eÄŸitilmiÅŸti?" sorusunun cevabÄ±nÄ± biliriz.

### Ä°ÅŸ AkÄ±ÅŸÄ± Orkestrasyonu (Pipeline Orchestration)
Bir RAG sisteminin veri hazÄ±rlama (indeksleme) sÃ¼reci ÅŸÃ¶yledir: "PDF'leri indir" -> "ParÃ§ala" -> "Embeddings oluÅŸtur" -> "VektÃ¶r DB'ye yaz". Bu akÄ±ÅŸÄ±n her gece otomatik Ã§alÄ±ÅŸmasÄ± gerekir.
* **AraÃ§lar:** `Airflow`, `Prefect` veya `Kubeflow Pipelines` gibi araÃ§lar, bu karmaÅŸÄ±k baÄŸÄ±mlÄ±lÄ±klarÄ± olan iÅŸ akÄ±ÅŸlarÄ±nÄ± tanÄ±mlamamÄ±zÄ±, zamanlamamÄ±zÄ± ve baÅŸarÄ±sÄ±z olduÄŸunda yeniden denememizi saÄŸlar.

## 4. Strateji ve ÃœrÃ¼n: MÃ¼hendisin PusulasÄ± ğŸ§­
Teknoloji, amaÃ§ deÄŸil araÃ§tÄ±r. DoÄŸru aracÄ± seÃ§mek, teknik olduÄŸu kadar stratejik bir karardÄ±r.

### Maliyet Modellemesi (Tokenomics)
"Bu yeni RAG Ã¶zelliÄŸini devreye alÄ±rsak, OpenAI/Anthropic faturamÄ±z ay sonunda ne kadar artar?" Bu sorunun cevabÄ±nÄ± Ã¶nceden modelleyebilmek, bir Senior Engineer'Ä±n gÃ¶revidir. KullanÄ±cÄ± baÅŸÄ±na ortalama token maliyetini hesaplayabilmek gerekir.

### Ä°nÅŸa Et vs. SatÄ±n Al vs. Uyarla (Build vs. Buy vs. Adapt)
* **Buy (SatÄ±n Al):** OpenAI API'sini ne zaman kullanmalÄ±yÄ±z? (HÄ±zlÄ± pazara Ã§Ä±kÄ±ÅŸ, en iyi genel zeka).
* **Adapt (Uyarla):** AÃ§Ä±k kaynak Llama 3'Ã¼ (self-host) ne zaman tercih etmeliyiz? (Veri gizliliÄŸi, maliyet kontrolÃ¼, Ã¶zelleÅŸtirme).
* **Build (Ä°nÅŸa Et):** Ne zaman sÄ±fÄ±rdan kendi modelimizi (pre-training) eÄŸitmeliyiz? (Genellikle asla, ancak Ã§ok niÅŸ bir alanda (Ã¶rn. antik SÃ¼mer dili) Ã§alÄ±ÅŸÄ±yorsanÄ±z belki).

### AI ÃœrÃ¼n YÃ¶netimi (AI Product Management) GÃ¶zÃ¼yle DÃ¼ÅŸÃ¼nme
Bir Ã¼rÃ¼n yÃ¶neticisi gibi dÃ¼ÅŸÃ¼nebilmek. "Modelin doÄŸruluÄŸu %80, bu yeterli mi?" Cevap: "KullanÄ±m alanÄ± ne?". EÄŸer **"e-posta taslaÄŸÄ±"** ise evet. EÄŸer **"tÄ±bbi teÅŸhis"** ise kesinlikle hayÄ±r. Hata payÄ±nÄ±n kabul edilebilir olduÄŸu ve **Human-in-the-Loop (Ä°nsan-DÃ¶ngÃ¼de)** bir tasarÄ±mÄ±n (modelin Ã¶nerisini bir uzmanÄ±n onaylamasÄ±) nerede zorunlu olduÄŸunu anlamak, teknik bir karardan Ã§ok bir Ã¼rÃ¼n ve etik kararÄ±dÄ±r.