# Bölüm 6: OpenAI API - Bir Modeli Ürüne Dönüştürme Kılavuzu
Önceki bölümlerde, kapalı ve açık kaynaklı büyük dil modellerinin (LLM'ler) yeteneklerini inceledik. Ancak bir modelin "güçlü" olması, onun "kullanışlı" olduğu anlamına gelmez. Bir modeli potansiyel bir değerden, gerçek bir ürüne dönüştüren köprü, **Uygulama Programlama Arayüzü'dür (API)**.

OpenAI API, bu devrimin ön saflarında yer alarak, GPT, DALL-E (görüntü üretimi) ve Whisper (konuşma tanıma) gibi karmaşık modelleri, basit bir REST API çağrısı kadar erişilebilir hale getirdi. Bu bölümde, bu API'nin nasıl çalıştığını, kısıtlamalarını ve bir mühendisin onu verimli kullanmak için bilmesi gerekenleri ele alacağız.

## 1. Ana İşlem Motoru: Chat Completions API
OpenAI, başlangıçta `Completions API` (sadece metni tamamlama) ile yola çıksa da, modern ve en güçlü yaklaşım `Chat Completions API`'dir. Bu API, GPT-3.5, GPT-4 ve yeni nesil modellerle etkileşim kurmanın standart yoludur ve basit bir metin tamamlamadan çok daha fazlasını, yani diyaloğu yönetmek için tasarlanmıştır.

Başarısının sırrı, mesajları yapılandırma biçiminde yatar. API'ye gönderilen her istek, bir mesaj listesi (dizisi) içerir ve her mesajın bir "rolü" vardır:

-   **`system` (Sistem):** Bu, tüm konuşmanın "meta-talimatıdır". Modelin kişiliğini, uyması gereken kuralları, tonunu ve amacını belirler. Bu, genellikle bir kez ayarlanır ve değiştirilmez.
    -   *Örnek:* "Sen, yalnızca JSON formatında cevap veren bir API asistanısın."
-   **`user` (Kullanıcı):** Son kullanıcının veya uygulamanın girdisidir. Soruyu, talimatı veya isteği içerir.
    -   *Örnek:* "Bana Türkiye'nin en yüksek dağı hakkında bilgi ver."
-   **`assistant` (Asistan):** Modelin önceki cevaplarıdır. Bir konuşma geçmişini sürdürmek için bu kritik öneme sahiptir. API'ye bir `user` mesajıyla birlikte önceki `user` ve `assistant` mesajlarını da göndererek, modelin bağlamı (context) hatırlamasını ve diyaloğu sürdürmesini sağlarsınız.

Bu yapı, modelin durumu (state) olmayan bir API çağrısını, durum bilgisine sahip (stateful) bir sohbete dönüştürmenin mühendislik çözümüdür.

## 2. API ile İletişim Sanatı: Prompt Yazımı (Prompt Engineering)
Bir LLM ile çalışırken, "kod" yazmak yerine "prompt" yazarız. Prompt, modele ne yapacağını söyleyen talimattır. Basit bir soru sormaktan, karmaşık bir belgeyi analiz etmesini istemeye kadar her şey bir prompt ile başlar.

Etkili bir prompt, belirsizliği ortadan kaldırır ve modelden istenen çıktıyı alma şansını en üst düzeye çıkarır.

-   **Zayıf Prompt:** "Yenilenebilir enerjiyi anlat." (Çok genel. Ne kadar detaylı? Hangi formatta?)
-   **Güçlü Prompt:**
    -   Konu: Yenilenebilir Enerjinin Temel Faydaları
    -   Aşağıdaki formatı kullanarak bir özet oluştur:
        -   Başlık 1: [Faydayı buraya yaz]
        -   Başlık 2: [Faydayı buraya yaz]
        -   Başlık 3: [Faydayı buraya yaz]
    -   Ton: Profesyonel ve bilgilendirici.
    -   Kitle: Konuya yeni başlayanlar.

Daha da ileri seviyede, **Few-Shot Prompting** (birkaç örnekle öğretme) gibi teknikler kullanarak, modelinize çıktının tam olarak nasıl görünmesi gerektiğini (örn. JSON formatı, şiir stili) örneklerle gösterebilirsiniz.

## 3. Prototip Alanı: OpenAI Playground
Prompt mühendisliği bir deneme-yanılma sürecidir. Her deneme için kod yazmak verimsizdir. **OpenAI Playground**, bu süreci hızlandıran interaktif bir web arayüzüdür.

Playground, bir mühendisin bir laboratuvarıdır:
-   Farklı **`system`** rollerini test etmenizi sağlar.
-   **`temperature`** (çıktının ne kadar yaratıcı/rastgele olacağı) veya **`top_p`** gibi parametreleri anlık olarak değiştirmenizi sağlar.
-   Farklı modellere (örn. GPT-4o vs. GPT-4 Turbo) aynı prompt'u gönderip performanslarını karşılaştırmanızı sağlar.

Bir uygulama geliştirmeden önce, en verimli prompt'u bulana kadar Playground'da iterasyon yapmak, en iyi mühendislik pratiğidir.

## 4. Kısıtlamalar ve Maliyet: Token Ekonomisi
OpenAI API'yi kullanmak, bir bilgisayar oyunundaki "mana" (büyü gücü) yönetimine benzer. Buradaki "mana", **token**'dır ve her şey onun etrafında döner.

### Token Nedir?
Token, bir kelimenin tamamı veya bir parçası olabilen bir metin birimidir. Örneğin, "tokenization" kelimesi "token" ve "ization" olarak iki token olabilirken, "a" harfi tek bir token olabilir. Ortalama olarak, İngilizce'de 100 token yaklaşık 75 kelimeye denk gelir.

### Token Sayımı (Token Counting)
API'ye gönderdiğiniz her şey (prompt, sistem mesajı, konuşma geçmişi) ve API'den aldığınız her cevap token olarak sayılır. Bu sayımı yapmak (örneğin OpenAI'nin **`tiktoken`** kütüphanesi ile), iki kritik nedenden ötürü zorunludur:

1.  **Maliyet:** Fiyatlandırma, işlenen toplam token sayısına göredir.
2.  **Sınırlar:** Her modelin bir "bağlam penceresi" (context window) yani maksimum token limiti vardır.

### Maksimum Token Limiti (Bağlam Penceresi)
Bu, bir modelin tek seferde "hatırlayabildiği" veya işleyebildiği toplam token miktarıdır.
-   GPT-3 (eskiden): 4.096 token
-   GPT-4: 8.192, 32.768 token'lık versiyonlar
-   GPT-4 Turbo: 128.000 token

Bu limit, **girdi (prompt) + çıktı (cevap)** toplamıdır. Örneğin, 32K'lık bir modelde 30K token'lık bir prompt gönderirseniz, modelin size verebileceği cevabın uzunluğu en fazla 2K token olabilir. Bu bütçeyi yönetmek, özellikle uzun konuşma geçmişlerini veya büyük belgeleri işlerken uygulamanın mimarisini doğrudan etkiler.

## 5. Fiyatlandırma ve Optimizasyon
Maliyet, token sayımına dayalıdır. Ancak burada kritik bir mühendislik detayı vardır: Fiyatlandırma genellikle **asimetriktir**.

### Girdi Token'ları (Input) vs. Çıktı Token'ları (Output)
Çoğu model (örneğin GPT-4o) için, API'ye gönderdiğiniz **girdi token'ları** (prompt'unuz) için ödediğiniz ücret, modelin sizin için ürettiği **çıktı token'larından** (cevaptan) çok daha **ucuzdur**.

Bu asimetri, mühendislik kararlarını doğrudan etkiler:
-   **RAG (Geri Getirme Destekli Üretim)** sistemlerinde, modele uzun dokümanları (girdi) göndermek, modelin uzun özetler (çıktı) üretmesinden daha ucuza gelebilir.
-   Uygulamanızın maliyet profilini (çok girdi/az çıktı mı, yoksa az girdi/çok çıktı mı) anlamak, bütçe optimizasyonu için şarttır.

## 6. Nihai Özelleştirme: İnce Ayar (Fine-Tuning)
Prompt mühendisliği, modele ne yapacağını "söylemektir". İnce ayar (fine-tuning) ise modelin "davranışını değiştirmektir".

OpenAI API, önceden eğitilmiş modelleri (GPT-3.5 gibi) kendi özel veri setinizle eğitmenize olanak tanır. Bu, genellikle yüzlerce veya binlerce yüksek kaliteli "prompt" ve "ideal cevap" çiftinden oluşan bir JSONL dosyası yükleyerek yapılır.

### Ne Zaman Fine-Tuning Gerekir?
-   **Stil ve Ton:** Modelin her zaman belirli bir formatta (örn. şirketinizin marka sesiyle) cevap vermesini istiyorsanız.
-   **Karmaşık Görevler:** Prompt ile öğretilemeyecek kadar karmaşık veya alana özgü (domain-specific) görevler için (örn. özel bir kod dilini çevirmek).
-   **Prompt Optimizasyonu:** Modelden istediğiniz cevabı almak için çok uzun ve karmaşık (ve dolayısıyla pahalı) prompt'lar yazmak zorunda kalıyorsanız. Fine-tuning, bu karmaşık talimatları modelin "içine" yerleştirerek prompt'larınızı kısaltmanıza ve toplam token maliyetini düşürmenize yardımcı olabilir.

Fine-tuning, bir kerelik eğitim maliyeti ve (genellikle) daha yüksek bir kullanım maliyeti olan, ancak en üst düzeyde özelleştirme sunan ileri seviye bir tekniktir.