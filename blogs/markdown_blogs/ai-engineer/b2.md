## Bölüm 2: Modern Yapay Zekanın Temel Kavramları

### 1. AI vs. AGI (Yapay Zeka vs. Yapay Genel Zeka)
Bu ayrım, bir AI projesinin kapsamını ve hedeflerini belirlerken en temel stratejik farktır.

-   **AI (Artificial Intelligence / Yapay Zeka):** Bugün kullandığımız ve geliştirdiğimiz neredeyse tüm yapay zeka sistemlerini ifade eder. Buna **Dar Yapay Zeka (Narrow AI)** da denir. Bu sistemler, belirli bir görevi (resimdeki nesneleri tanıma, metni çevirme, Go oynama) insanüstü bir başarıyla yapacak şekilde tasarlanmıştır, ancak bu görevin dışına çıktıklarında tamamen yeteneksizdirler. Bir satranç motoru size hava durumunu söyleyemez.
    -   **Senior Perspektifi:** Bir Senior AI Engineer'ın işi, bu "dar" yetenekleri kullanarak gerçek iş problemlerini çözmektir. Projenin sınırlarını net bir şekilde çizmek, gerçekçi beklentiler oluşturmak ve modelin başarısız olacağı senaryoları (edge cases) öngörmek en önemli sorumluluklarındandır.

-   **AGI (Artificial General Intelligence / Yapay Genel Zeka):** İnsanın yapabildiği herhangi bir zihinsel görevi anlayabilen, öğrenebilen ve uygulayabilen teorik bir yapay zeka türüdür. AGI, bağlamı anlar, farklı alanlar arasında akıl yürütebilir ve yeni görevlere kendi kendine adapte olabilir. Henüz AGI seviyesinde bir sistem mevcut değildir.
    -   **Senior Perspektifi:** AGI, şu an için bir araştırma hedefidir. Pratik sistemler tasarlarken AGI varsayımıyla hareket etmek, projenin başarısız olmasına yol açar. Senior mühendis, mevcut dar AI'ın sınırlarını bilerek güvenilir ve öngörülebilir sistemler tasarlamak zorundadır.

### 2. LLMs (Large Language Models / Büyük Dil Modelleri)
LLM'ler, `Transformer` mimarisine dayanan ve devasa metin verileri üzerinde eğitilmiş derin öğrenme modelleridir. Onları özel kılan şey, belirli bir görev için programlanmamış olmaları, bunun yerine metin verisindeki istatistiksel kalıpları öğrenerek dilin "genel" bir anlayışını geliştirmeleridir.

-   **Teknik Nüans:** Başarılarının temelinde yatan **Self-Attention (Öz-Dikkat)** mekanizması, bir cümlenin her kelimesinin diğer tüm kelimelerle olan ilişkisini ve önemini dinamik olarak hesaplamasına olanak tanır. Bu, uzun mesafeli bağımlılıkları ve bağlamı anlamalarını sağlar.
-   **Senior Perspektifi:**
    -   **Scaling Laws (Ölçekleme Yasaları):** Model boyutu (parametre sayısı), veri seti boyutu ve hesaplama gücü arttıkça, LLM'lerin performansı öngörülebilir bir şekilde artar ve belirli bir ölçekten sonra **emergent abilities (beliren yetenekler)** ortaya çıkar. Yani, model küçükken yapamadığı (örn. matematik problemi çözme, kod yazma) yetenekleri, yeterince büyüdüğünde birdenbire kazanır.
    -   **Base Models vs. Instruction-Tuned Models:** `Base model` (örn. GPT-3), metni devam ettirmeye odaklıdır. `Instruction-Tuned model` (örn. ChatGPT, InstructGPT) ise, base modelin üzerine insan geri bildirimleriyle (`RLHF`) eğitilerek komutları daha iyi takip etmesi ve daha "yardımcı" olması sağlanmış modeldir. Bir ürün geliştirirken hangi tip modeli kullanacağınız kritik bir karardır.

### 3. Training vs. Inference (Eğitim vs. Çıkarım)
Bunlar bir modelin yaşam döngüsündeki iki ana aşamadır.

-   **Training (Eğitim):** Modelin, verideki kalıpları öğrendiği, yoğun hesaplama gerektiren süreçtir.
    -   **Pre-training (Ön-eğitim):** LLM'lerin internet ölçeğindeki devasa verilerle, genellikle "bir sonraki kelimeyi tahmin et" gibi bir hedefle (self-supervised) eğitildiği, aylar süren ve milyonlarca dolara mal olan aşama.
    -   **Fine-tuning (İnce Ayar):** Ön-eğitimden geçmiş bir modelin, daha küçük ve göreve özel bir veri setiyle (supervised) eğitilerek belirli bir alanda (örn. hukuk metinlerini anlama, müşteri hizmetleri cevapları üretme) uzmanlaştırılması.
    -   **Senior Perspektifi:** Eğitim, bir **offline (çevrimdışı)** işlemdir. Buradaki ana zorluklar; dağıtık hesaplama (distributed computing), veri kalitesi ve maliyettir. **Parameter-Efficient Fine-Tuning (PEFT)** gibi (örn. `LoRA`) teknikler, milyarlarca parametreli modellerin tamamını değil, sadece küçük bir kısmını güncelleyerek fine-tuning maliyetini dramatik şekilde düşürmeyi sağlar. Bu, senior mühendisin bilmesi gereken kritik bir optimizasyon tekniğidir.

-   **Inference (Çıkarım):** Eğitilmiş bir modelin, yeni veri noktaları için tahminlerde bulunmak üzere kullanıldığı süreçtir. Bu, kullanıcıya hizmet veren **canlı (online)** sistemdir.
    -   **Senior Perspektifi:** Inference'daki en önemli metrikler **latency (gecikme)** ve **throughput (verim)**'dir. Amaç, en hızlı ve en ucuz şekilde en fazla sayıda tahmini yapmaktır. Bunun için `Quantization` (modelin ağırlıklarını daha düşük hassasiyetli sayılara, örn. 32-bit'ten 8-bit'e dönüştürerek modeli küçültme ve hızlandırma), `pruning` (önemsiz bağlantıları budama) ve özel donanımlar (GPU, TPU) kullanılır. Modelin nereye (edge cihazı mı, bulut mu) deploy edileceği, bu optimizasyon kararlarını doğrudan etkiler.

### 4. Embeddings & Vector Databases (Gömülüler ve Vektör Veritabanları)
Bu ikili, modern anlamsal (semantic) arama ve RAG sistemlerinin kalbidir.

-   **Embeddings (Gömülüler):** Kelime, cümle veya resim gibi karmaşık ve yapısal olmayan verilerin, anlamsal özünü yakalayan yoğun, sayısal vektörlere dönüştürülmüş halidir. Aynı anlama gelen iki farklı cümle, bu vektör uzayında birbirine çok yakın olacaktır.
    -   **Senior Perspektifi:** Embedding, bir **temsil öğrenme (representation learning)** biçimidir. Hangi embedding modelini (örn. `OpenAI's text-embedding-ada-002`, `Sentence-BERT`) seçeceğiniz, görevinize (arama mı, sınıflandırma mı?), maliyete ve performans ihtiyacınıza bağlıdır. Vektörlerin boyut sayısı (dimensionality) da hız ve doğruluk arasında bir trade-off yaratır.

-   **Vector Databases (Vektör Veritabanları):** Milyonlarca veya milyarlarca embedding vektörünü depolamak ve belirli bir vektöre en yakın komşularını milisaniyeler içinde bulmak için optimize edilmiş özel veritabanlarıdır. (Örn: `Pinecone`, `Weaviate`, `Milvus`).
    -   **Senior Perspektifi:** Geleneksel veritabanları bu işi yapamaz. Vektör veritabanları, **Approximate Nearest Neighbor (ANN)** algoritmaları (örn. `HNSW`, `LSH`) kullanarak %100 doğruluktan küçük bir miktar feragat ederek hızı binlerce kat artırır. Bir senior mühendis, projenin ihtiyacına göre indeksleme stratejisini (örn. hız vs. doğruluk vs. bellek kullanımı) doğru şekilde yapılandırmalıdır.

### 5. RAG (Retrieval-Augmented Generation / Geri Getirme Destekli Üretim)
LLM'lerin en büyük iki sorununu (bilgi eksikliği/güncel olmama ve halüsinasyon) çözmek için tasarlanmış güçlü bir mimari desendir.

**Süreç:**
1.  **Retrieve (Geri Getir):** Kullanıcının sorusu bir embedding'e dönüştürülür. Bu embedding kullanılarak vektör veritabanından en alakalı bilgi parçacıkları (dokümanlar, notlar vb.) bulunur.
2.  **Augment (Destekle):** Bulunan bu bilgi parçacıkları, kullanıcının orijinal sorusuyla birlikte, LLM'e gönderilecek olan prompt'a **bağlam (context)** olarak eklenir.
3.  **Generate (Üret):** LLM'e şöyle bir komut verilir: "Bu bağlamı kullanarak şu soruyu cevapla." LLM, cevabını bu sağlanmış bilgiye dayandırmak zorunda kalır.

-   **Senior Perspektifi:** RAG, bir modelin bilgisini fine-tuning yapmadan "genişletmenin" en etkili ve maliyet-etkin yoludur. Bu bir sistem tasarımı problemidir. Başarısı, "retriever" (geri getirme) bileşeninin kalitesine doğrudan bağlıdır. İyi bir RAG sistemi, geri getirme (retrieval) ve üretme (generation) adımları arasında hassas bir denge kurar.

### 6. AI Agents (Yapay Zeka Ajanları)
LLM'leri pasif bir metin üreticiden, hedeflere ulaşmak için otonom kararlar alabilen ve araçlar kullanabilen aktif bir "ajan" haline getirme konseptidir.

**Çalışma Döngüsü:** Bir ajan temel olarak bir **düşün-eylem-gözlem (thought-action-observation)** döngüsünde çalışır.
-   **Thought (Düşünce):** LLM, verilen görevi başarmak için bir sonraki adımın ne olması gerektiğini planlar.
-   **Action (Eylem):** LLM, bu planı gerçekleştirmek için bir araç kullanmaya karar verir. Bu araç bir arama motoru API'si, bir hesap makinesi, bir kod yorumlayıcısı veya şirket içi başka bir API olabilir.
-   **Observation (Gözlem):** Ajan, aracın çıktısını (API yanıtı, kodun sonucu) gözlemler ve bu yeni bilgiyi kullanarak döngünün başına döner ve yeni bir "düşünce" üretir.

-   **Senior Perspektifi:** Ajanlar, AI'ın geleceği olarak görülse de pratikte güvenilirliklerini sağlamak çok zordur. Bir senior mühendis, ajanın sonsuz döngüye girmesini, bütçeyi aşmasını veya yanlış araçları kullanmasını engelleyecek kısıtlamalar ve güvenlik mekanizmaları tasarlamalıdır. `LangChain` ve `LlamaIndex` gibi framework'ler bu ajanları oluşturmayı kolaylaştırır, ancak üretim ortamında stabil çalışmasını sağlamak ileri düzey bir mühendislik problemidir.

### 7. Prompt Engineering (Prompt Mühendisliği)
LLM'lerden istenen çıktıyı en doğru ve tutarlı şekilde alabilmek için girdi metnini (prompt) tasarlama ve optimize etme disiplinidir.

**Temel Tekniklerin Ötesi:**
-   **Few-Shot Prompting:** Modele ne istediğinizi göstermek için prompt'un içine birkaç örnek (soru-cevap çifti) eklemek.
-   **Chain-of-Thought (CoT) Prompting:** Modelden bir problemi "adım adım düşünerek" çözmesini istemek. Bu, özellikle mantıksal akıl yürütme gerektiren görevlerde performansı dramatik şekilde artırır.

-   **Senior Perspektifi:** Prompt mühendisliği, sadece deneme-yanılma değildir. Bu, bir test ve otomasyon sürecidir. Senior mühendisler, prompt'ları kod gibi ele alır:
    -   **Prompt Şablonları (Templates):** Değişken kısımları olan, yeniden kullanılabilir prompt'lar oluşturmak.
    -   **Prompt Değerlendirme (Evaluation):** Bir grup test senaryosu (test case) hazırlayıp, farklı prompt versiyonlarının bu senaryolardaki performansını otomatik olarak değerlendiren sistemler kurmak.
    -   **Prompt Versiyonlama:** Hangi prompt versiyonunun hangi modelle en iyi sonucu verdiğini takip etmek.

---
*Bu kavramlar, birbirine bağlı bir ekosistem oluşturur. Embeddings, vektör veritabanlarını mümkün kılar; bu ikisi ise etkili bir RAG sisteminin temelidir. RAG, LLM'lerin daha güvenilir hale gelmesini sağlar. Ve tüm bu bileşenler, karmaşık görevleri yerine getiren bir AI Agent'ının araç setinde bulunabilir. Tüm bu süreç, training ile başlar, inference ile son kullanıcıya ulaşır ve prompt engineering ile sürekli olarak optimize edilir.*