# Bölüm 4: Çıktıyı Evcilleştirmek: Uzunluk, Format ve Tekrarlılık Kontrolü
Bir LLM'den aldığımız cevabın kalitesi kadar, o cevabın formatı da kritiktir. Bir JSON beklerken bir paragraf almak, bir API'nin çökmesi için yeterlidir. Bu bölümde, çıktıyı "evcilleştirmek" için kullanılan, maliyeti düşüren ve güvenilirliği artıran teknik parametreleri ele alacağız.

## 1. Uzunluk Kontrolü (Kaba Kuvvet): Max Tokens
**Max Tokens (Maksimum Token)**, bir modelin bir yanıtta üreteceği en fazla token sayısını belirleyen bir güvenlik ayarıdır.

* **Teknik olarak ne yapar:** Model, token-by-token (Bölüm 2'de gördük) üretim yaparken, bu limite ulaştığı an aniden durur.
* **Yaygın Yanılgı (Kritik Uyarı):** `Max Tokens`'ı düşürmek (örn. 50'ye ayarlamak), modelin daha **"kısa"** veya **"özet"** bir cevap vermesini sağlamaz. Modelin daha öz bir cevap vermesini istiyorsanız, bunu prompt (talimat) yoluyla ("Cevabını tek cümlede özetle.") istemelisiniz. `Max Tokens=50` ayarlamak, modelin 500 token'lık harika bir cevabının 50. token'ında (belki bir cümlenin tam ortasında) kesilmesine neden olabilir.
* **Ne Zaman Kullanılır:**
    * **Maliyet Kontrolü:** Modelin sonsuz bir döngüye girmesini veya binlerce token üreterek faturayı şişirmesini engeller. Bu bir **"sigortadır"**.
    * **Performans:** Daha az token, daha hızlı API yanıt süresi demektir.
    * **Basit Sınırlama:** ReAct (Ajanlar) gibi mimarilerde, modelin istenen Action JSON'undan sonra gereksiz "Thought" (Düşünce) adımlarını üretmesini engellemek için (daha az verimli bir yol olsa da) kullanılabilir.

## 2. Format Kontrolü (Cerrahi Yöntem): Stop Sequences
Bu, `Max Tokens`'ın kaba kuvvet yaklaşımının aksine, son derece hassas, cerrahi bir kontrol yöntemidir. **Stop Sequences (Durdurma Dizileri)**, modelin metin üretirken karşılaştığı anda üretimi hemen durdurmasını sağlayan belirli karakter dizileridir (string).

* **Teknik olarak ne yapar:** Model, bir sonraki token'ı üretmeden önce, ürettiği son metin dizisinin bir durdurma dizisiyle bitip bitmediğini kontrol eder. Eğer biterse, üretim tamamlanmış sayılır.
* **Neden Max Tokens'tan Üstündür:** Çünkü çıktıyı mantıksal bir sonlanma noktasına göre keser, rastgele bir token sayısına göre değil.
* **Kullanım Alanları (Üretim Seviyesi Örnekler):**
    * **Yapılandırılmış Veri (JSON/YAML):** Modelden bir JSON üretmesini istiyorsunuz. `stop=["}"]` ayarlayarak, modelin JSON nesnesini kapattığı `}` karakterinden sonra gereksiz yorumlar (// İşte JSON'unuz!) eklemesini engellersiniz.
    * **Few-Shot (Bölüm 1):** Modele `Soru: ... Cevap: ... \n\n` formatında örnekler verdiniz. `stop=["\n\n"]` ayarlayarak, modelin bir sonraki soruya geçmeye çalışmasını veya kendi kendine yeni sorular uydurmasını engellersiniz.
    * **ReAct Ajanları (En Kritik Kullanım):** Bir ajanın `Thought -> Action -> Observation` döngüsünü hatırlayalım. Biz sadece `Action` JSON'unu istiyoruz. Prompt'umuzu `...Action: {json_output}Observation:` şeklinde yapılandırırız. Eğer `stop=["Observation:"]` ayarlarsak, model `Action` JSON'unu üretir ve "Observation:" kelimesini üreteceği anda durur. Bu, tam olarak ihtiyacımız olan temiz, ayrıştırılabilir (parsable) JSON'u almamızı garanti eder.

## 3. Tekrarlılık Kontrolü (İçerik Kalitesi): Repetition Penalties
Özellikle yüksek `Temperature` (Sıcaklık) ayarlarında, LLM'ler "takılıp kalabilir" ve aynı kelimeleri veya cümleleri tekrar tekrar (Ben bir yapay zekayım. Ben bir yapay zekayım...) üretebilirler. Tekrarlılık cezaları, bu davranışı engellemek için modelin olasılık dağılımına müdahale eder.

Bu cezaların iki ana türü vardır ve aralarındaki fark tekniktir:

### a) Frequency Penalty (Sıklık Cezası)
Bu ceza, bir token'ın metinde ne kadar sık kullanıldığına bağlı olarak ölçeklenir.

* **Nasıl Çalışır:** Bir token'ın olasılığını, o token'ın şimdiye kadar metinde kaç kez geçtiğine (frekansına) göre azaltır.
* **Analoji:** "Diminishing returns" (Azalan verim). Bir kelimeyi ne kadar çok kullanırsanız, onu bir sonraki sefer kullanmanız o kadar "pahalı" (düşük olasılıklı) hale gelir.
* **Ne Zaman Kullanılır:** Modelin belirli anahtar kelimelere veya jargonlara "fazla takılmasını" engellemek istediğiniz uzun metinler (makaleler, özetler) için iyidir.

### b) Presence Penalty (Mevcudiyet Cezası)
Bu ceza sabit bir cezadır ve bir token'ın metinde en az bir kez görünüp görünmediğine bakar.

* **Nasıl Çalışır:** Bir token metinde bir kez bile kullanıldıysa, o token'ın gelecekteki olasılığına sabit bir ceza (penalty) uygulanır. Bu ceza, token'ı 2. veya 10. kez kullanmanızda artmaz.
* **Analoji:** "Tek seferlik vergi." Bir kelimeyi kullandığınız anda bir "vergi" ödersiniz ve bu, onu tekrar kullanmanızı (ilk kullanımdan daha) az olası hale getirir.
* **Ne Zaman Kullanılır:** Modelin yeni konulara veya yeni kelimelere geçmesini teşvik etmek, yani kelime dağarcığını çeşitlendirmek istediğinizde kullanılır. Yaratıcı beyin fırtınaları veya konsept oluşturma için harikadır.

---

## Özetle:
Bir üretim (production) sistemi tasarlarken, bu parametreler birlikte kullanılır:

* **Prompt (Talimat):** Modele ne yapacağını söyler (örn. "JSON üret").
* **Temperature (Bölüm 3):** Cevabın karakterini belirler (örn. 0.0 - olgusal JSON).
* **Stop Sequences:** Cevabın formatını garanti eder (örn. `stop=["}"]`).
* **Max Tokens:** Cevabın sınırlarını (ve maliyetini) korur.
* **Repetition Penalties:** Cevabın kalitesini artırır (eğer serbest metin üretiyorsa).