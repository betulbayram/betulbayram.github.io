# Bölüm 1: Prompt Engineering Nedir? - LLM'lerin "Programlama Dili"
**Prompt Engineering** (Komut/Talimat Mühendisliği), Büyük Dil Modellerinden (LLM'ler) istenen çıktıları elde etmek için etkili girdiler tasarlama pratiğidir. Bu, yapay zekanın potansiyelini ortaya çıkarmak için çok önemli olan evrensel bir beceridir ve herhangi bir programlama bilgisi gerektirmez.

Bu, LLM'ler için bir "programlama" eylemidir. Geleneksel programlamada, bir hedefe ulaşmak için Python veya Java gibi katı kurallara (sözdizimi/syntax) sahip bir dil kullanırız. Bilgisayara tam olarak ne yapacağını emrederiz. Prompt mühendisliğinde ise, katı bir sözdizimi yerine **doğal dilin** (Türkçe, İngilizce vb.) nüanslarını kullanarak modeli yönlendiririz.

## Temel Kavramlar: Prompt ve LLM
Bu mühendisliği anlamak için iki temel bileşeni bilmemiz gerekir: "Prompt"un ne olduğu ve "LLM"in nasıl çalıştığı.

### 1. Prompt (Komut/Talimat) Nedir?
**Prompt**, bir yanıt veya tahmin üretmesi için bir Büyük Dil Modeline (LLM) sağlanan girdidir. Modelin çıktı üretme sürecine rehberlik eden **talimat** veya **bağlam (context)** görevi görür. Etkili bir prompt; açık, spesifik, iyi yapılandırılmış ve hedef odaklıdır. Modelden alacağınız yanıtın doğruluğu ve ilgililiği, doğrudan bu girdinin kalitesine bağlıdır.

### 2. LLM'ler Nasıl Çalışır? (Tahmin Motorları)
LLM'ler, metni sıralı bir şekilde işleyen sofistike **tahmin motorları** olarak çalışır. Geleneksel programlama gibi "düşünmezler"; bunun yerine, önceki token'lar (kelime parçaları) arasındaki ilişkilere ve devasa eğitim verilerinden öğrendikleri kalıplara dayanarak bir sonraki **token'ı** (kelime veya kelime parçası) tahmin ederler.

Bu, doğrudan tek bir kelimeyi seçmek gibi değildir. Model, olası tüm sonraki token'lar üzerinde bir olasılık dağılımı (%30 'kedi', %20 'köpek', %1 'roket') oluşturur. Daha sonra, `temperature` (sıcaklık) veya `top-K` gibi parametreler kullanılarak bu olasılık listesinden bir örnekleme yapılır. Model, tahmin edilen token'ı mevcut metne ekler ve tüm süreci bir sonraki token için (artık yeni bir bağlamla) tekrarlar.

Bu **token-by-token (token token)** tahmin süreci, LLM'lerin bu kadar tutarlı ve bağlama uygun metinler üretmesinin temelini oluşturur.

## Neden Sadece "Soru Sormak" Değil, "Mühendislik"?
LLM'lerin bir "tahmin motoru" olduğunu anladığımızda, neden basitçe "soru sormanın" yetmediği de ortaya çıkar. **"Garbage In, Garbage Out"** (Çöp Girdi, Çöp Çıktı) prensibi, LLM'ler için her zamankinden daha geçerlidir.

* **Zayıf Prompt:** "Bana RAG'ı anlat."
    * **Neden Zayıf:** Model, bir sonraki token'ı tahmin ederken çok geniş bir olasılık alanına sahiptir. Kime cevap verdiğini (öğrenci, uzman?), hangi detay seviyesinde (giriş, teknik?) ve hangi formatta (liste, paragraf?) istediğinizi bilmez.
    * **Sonuç:** Genel, uzun, belki de çok teknik veya çok basit bir cevap.

* **Güçlü Prompt:** "Bir AI Engineer adayı olarak, RAG mimarisinin 'fine-tuning'e kıyasla avantajlarını ve dezavantajlarını özetleyen 3 maddelik bir liste hazırla. Ton, profesyonel ve teknik olsun."
    * **Neden Güçlü:** Bu prompt, modelin olasılık dağılımını kısıtlar. Onu "profesyonel" ve "teknik" token'lara, "liste" formatına ve "RAG vs. fine-tuning" konusundaki spesifik kalıplara yönlendirir.
    * **Sonuç:** Hedeflenmiş, formatlanmış, bağlama uygun ve amaca yönelik bir cevap.

Bu, "talimat" ile "mühendislik" arasındaki farktır.

## Bir Prompt'un Anatomisi: 4 Temel Bileşen
Üretim seviyesinde (production-grade) bir prompt, genellikle dört ana bileşenden oluşur. Bir prompt'u yazarken bu dört unsuru düşünmek, başarınızı garantiler:

1.  **Rol (Role):** Modele bir kişilik veya uzmanlık atamak. Bu, modelin cevap üretirken hangi "şapkayı" takacağını belirler.
    * *Örnek:* "Sen, 20 yıllık deneyime sahip bir siber güvenlik uzmanısın..."
2.  **Talimat (Instruction / Task):** Modelin yapmasını istediğiniz ana eylem veya görev.
    * *Örnek:* "...aşağıdaki kod bloğunu analiz et ve olası güvenlik açıklarını listele."
3.  **Bağlam (Context):** Modelin görevi yerine getirmek için ihtiyaç duyduğu ek bilgi. Bu, RAG sistemlerindeki geri getirilen (retrieved) dokümanlar, bir e-posta metni veya bir kullanıcı profili olabilir.
    * *Örnek:* "...Kod bloğu şudur: [kod buraya]..."
4.  **Çıktı Kısıtlamaları (Output Constraints / Format):** Cevabın nasıl görünmesi gerektiğine dair net kurallar. Bu, güvenilirlik ve otomasyon için en kritik kısımdır.
    * *Örnek:* "...Bulduğun açıkları JSON formatında, 'vulnerability' (açık) ve 'severity' (önem derecesi) anahtarlarıyla listele."

## Temel Teknikler: Zero-Shot vs. Few-Shot
Bir modelin bu talimatları anlamasını sağlamanın iki temel yolu vardır:

### 1. Zero-Shot (Sıfır Örnekli) Prompting
Bu, modelin hiçbir örnek görmeden, sadece talimatlara dayanarak bir görevi yerine getirmesini istemektir. Günlük sohbetlerimizin çoğu (ve yukarıdaki "Güçlü Prompt" örneği) aslında birer zero-shot prompt'tur. Güçlü modeller (GPT-4o, Claude 3 Opus) zero-shot görevlerde inanılmaz başarılıdır.

### 2. Few-Shot (Birkaç Örnekli) Prompting
Bu, prompt mühendisliğinin ilk "güçlendiricisi" (power-up) ve en temel tekniklerinden biridir. Modele sadece ne yapacağını söylemekle kalmaz, aynı zamanda **nasıl yapacağını birkaç örnekle gösterirsiniz.**

Bu, modelin istenen formatı veya stili taklit etmesini sağlar ve özellikle karmaşık veya belirsiz görevlerde performansı dramatik şekilde artırır.

**Örnek: Duygu Analizi**

**Zero-Shot (Başarısız Olabilir):**
> "Aşağıdaki cümlenin duygusunu sınıflandır: 'Bu kadar yavaş bir hizmeti daha önce hiç görmemiştim.'"
>
> *Modelin Muhtemel Cevabı:* "Cümle, hizmetin yavaşlığı hakkında bir yorum içeriyor." (İstenen formatta değil)

**Few-Shot (Başarılı):**
> "Aşağıdaki cümleleri 'Olumlu', 'Olumsuz' veya 'Nötr' olarak sınıflandır.
>
> Cümle: 'Toplantı beklediğimden verimli geçti.'
> Duygu: Olumlu
>
> Cümle: 'Proje bütçesi onaylandı.'
> Duygu: Nötr
>
> Cümle: 'Bu kadar yavaş bir hizmeti daha önce hiç görmemiştim.'
> Duygu:"
>
> *Modelin İstenen Cevabı:* `Olumsuz`

Model, sağladığınız kalıbı (pattern) tanır ve son örneği tam olarak istediğiniz formatta tamamlar. Bu, ince ayar (fine-tuning) yapmadan modelin davranışını yönlendirmenin en ucuz ve en hızlı yoludur.

Bu giriş bölümü, prompt'ları birer "mühendislik" ürünü olarak görmemizi sağladı. Artık temel bileşenleri ve en temel iki tekniği (Zero-shot, Few-shot) biliyoruz.