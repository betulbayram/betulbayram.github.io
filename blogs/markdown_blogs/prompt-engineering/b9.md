# Bölüm 9: Güvenilirliği Artırmak - Yanlılık, Tutarlılık ve Öz-Değerlendirme
Üretim seviyesinde bir sistem, sadece "doğru" cevaplar vermemeli, aynı zamanda **adil**, **tutarlı** olmalı ve **belirsizliğin farkında** olmalıdır. Bu bölüm, bu üç temel direği sağlamlaştıran tekniklere odaklanmaktadır.

## 1. Prompt Debiasing (Yanlılıktan Arındırma)

### Problem:
LLM'ler, internetten (yani insanlığın tüm kolektif önyargılarından) öğrendikleri verilerle eğitilir. Eğer dikkatli olmazsak, bu modeller ırksal, cinsiyetçi ve kültürel klişeleri sadece yansıtmakla kalmaz, aynı zamanda güçlendirir. Bu etik bir sorun olduğu kadar, ürününüzün belirli kullanıcı gruplarını dışlamasına neden olan ciddi bir ürün sorunudur.

### Teknikler:
Prompt'larımızı, bu yanlılıkları azaltacak şekilde kasıtlı olarak tasarlamalıyız.

#### Nötr Dil Kullanımı (Neutral Language)
Modeli belirli bir cinsiyete veya role yönlendiren zamirlerden ve sıfatlardan kaçının.
> **Yanlı (Biased):** "Bir doktorun maaş beklentisini yaz. **O**, kariyerinde..." (İngilizce'de `He` zamiri kullanmak modeli erkeğe yönlendirebilir.)
>
> **Yansız (Debiased):** "Bir tıp doktoru rolü için maaş beklentilerini listele. **Bu rol**..."

#### Çeşitlendirilmiş Örnekler (Diverse Examples - Few-Shot)
Bölüm 6'da gördüğümüz Few-Shot tekniği, yanlılığı düzeltmek için en güçlü aracımızdır. Eğer örnekleriniz yanlı ise, çıktınız da yanlı olacaktır.
> **Yanlı (Biased):**
> Örnek 1: Mühendis Ali, teknik bir sorun çözdü.
> Örnek 2: Hemşire Zeynep, hastaya baktı.
>
> **Yansız (Debiased):**
> Örnek 1: Mühendis Ayşe, teknik bir sorun çözdü.
> Örnek 2: Mühendis Ali, birim testi yazdı.
> Örnek 3: Hemşire Mehmet, hastaya baktı.
> Örnek 4: Hemşire Zeynep, vardiya planı yaptı.

#### Açık Talimatlar (Explicit Instructions)
Modele açıkça adil olmasını söylemek şaşırtıcı derecede etkilidir.
> **Örnek Talimat:** "Cevabını oluştururken, cinsiyet, ırk, yaş veya köken temelinde herhangi bir klişe veya varsayımda bulunmadığından emin ol. Tarafsız ve adil bir dil kullan."

---

## 2. Prompt Ensembling (Topluluk Yöntemiyle Tutarlılık)

### Problem:
Özellikle yaratıcılık için `Temperature`'ı (Bölüm 3) artırdığınızda veya karmaşık bir görevde, modelin aynı soruya verdiği cevaplar tutarsız olabilir. Bazen mükemmel, bazen hatalı cevaplar alabilirsiniz.

### Çözüm:
Tek bir prompt'un zekasına güvenmek yerine, bir "uzmanlar konseyi" oluşturun. **Prompt Ensembling**, aynı sorguyu birden fazla farklı prompt varyantı ile çalıştırmayı ve sonuçları birleştirerek daha sağlam (robust) bir cevap elde etmeyi amaçlar.

#### Teknik Akış:
* Aynı görevi yapan 3-5 farklı prompt tasarlayın (örn. biri Zero-shot, biri Few-shot, biri Rol Talimatı içeren).
* Kullanıcı sorgusunu bu 3-5 prompt'un hepsine aynı anda gönderin.
* Gelen sonuçları birleştirin.

#### Birleştirme Yöntemleri:
* **Çoğunluk Oylaması (Majority Voting):** (Sınıflandırma/Çıkarım için) 5 prompt'tan 3'ü "Olumlu" dediyse, nihai cevap "Olumlu"dur.
* **Ortalama Alma (Averaging):** (Sayısal skorlama için) "Bu metnin riskini 1-10 arası puanla." 3 prompt'un verdiği puanların (örn. 7, 9, 8) ortalamasını (8) alın.
* **Birleştirme (Aggregation):** (Metin üretimi için) 3 farklı özet üretmesini isteyin. Ardından, dördüncü bir "Birleştirici LLM" çağrısı yaparak "Bu 3 özeti al ve hepsinin ana fikrini içeren tek bir nihai özet oluştur." deyin.

### Dezavantajı:
Bu yöntem çok **pahalıdır**. 5 prompt kullanmak, 5 kat API maliyeti ve gecikme (latency) demektir. Bu nedenle, yalnızca yüksek güvenilirlik gerektiren (örn. finansal analiz, tıbbi veri sınıflandırma) kritik sistemlerde kullanılır.

---

## 3. LLM Self-Evaluation (Öz-Değerlendirme)

### Problem:
Modelin ürettiği cevabın kaliteli veya doğru olup olmadığını nasıl anlarız? Her çıktıyı manuel olarak kontrol edemeyiz.

### Çözüm:
Modelin kendisinden, kendi cevabını değerlendirmesini isteyin. LLM'ler, cevap üretmekte oldukları kadar, cevapları belirli kriterlere göre eleştirmekte de iyidirler. Bu, **meta-biliş (metacognition)** yaratma pratiğidir.

#### Teknik Akış (İki Aşamalı):
**Aşama 1 (Üretim):** Normal prompt'unuzla cevabı üretin.
> **Prompt 1:** "Fransız Devrimi'nin ana nedenleri nelerdir?"
> **Cevap 1:** "...Ana nedenlerden biri, Marie Antoinette'in 'Ekmek bulamıyorlarsa pasta yesinler' sözüdür..."

**Aşama 2 (Değerlendirme):** Orijinal soruyu ve modelin cevabını, eleştirel bir "Değerlendirici Prompt"a (Evaluator Prompt) verin.
> **Prompt 2:** "Soru: 'Fransız Devrimi'nin ana nedenleri nelerdir?' Cevap: '...Ana nedenlerden biri...' Bu cevabı 'Olgusal Doğruluk' ve 'Eksiksizlik' kriterlerine göre 1-5 arası puanla. Olgusal bir hata varsa açıkla."
> **Değerlendirme Cevabı:** "Olgusal Doğruluk: 2/5. Hata: 'Pasta yesinler' sözünün Marie Antoinette tarafından söylendiği tarihsel olarak kanıtlanmamıştır ve devrimin ana nedeni değildir. Bu bir atıftır."

### Kullanım:
Bu teknik, `RAGAS` gibi RAG değerlendirme (Bkz. Seri 1, Bölüm 20) framework'lerinin temelini oluşturur ve otomatik test (Bölüm 8) pipeline'ları için hayati önem taşır.

---

## 4. Calibrating LLMs (Güven Kalibrasyonu)

### Problem:
LLM'lerin en tehlikeli yönü, "halüsinasyon" (Bölüm 2) gördüklerinde bile son derece kendinden emin bir ton kullanmalarıdır. Bir şeyden %51 emin olduklarında da, %99 emin olduklarında da aynı yetkin dille konuşurlar.

### Çözüm (Kalibrasyon):
Modelin ifade ettiği güvenin (confidence), gerçek doğruluğu (accuracy) ile eşleşmesini sağlamaktır. Model, yanılma ihtimali yüksek olduğunda belirsizlik ifade etmelidir.

#### Prompt Yoluyla Kalibrasyon (Proxy):
Modeli, emin olmadığında bunu belirtmeye zorlayabiliriz.
* **Talimat:** "Sadece olgusal olarak doğrulayabildiğin cevapları ver. Eğer cevap eğitim verilerinde yoksa veya belirsizse, 'Bu konuda emin değilim' veya 'Birkaç olasılık var' şeklinde cevap ver."
* **Talimat (Skorlama):** "Cevabını 1-10 arası bir 'güven skoru' ile birlikte JSON formatında ver."

#### Teknik Not:
Bu "istenmiş" güven skorunun (modelin ürettiği `{"güven": 9}`) istatistiksel bir temeli yoktur; bu da cevabın bir parçasıdır ve halüsinasyon olabilir. Gerçek kalibrasyon, modelin çıktı olasılıklarını (logit'lerini) analiz etmeyi ve bu olasılıkları binlerce test örneği üzerinden gerçek doğruluk oranlarıyla karşılaştırarak (örn. Temperature Scaling) ayarlamayı içeren daha derin bir makine öğrenmesi tekniğidir.

Ancak prompt mühendisliği seviyesinde, modeli belirsizliği ifade etmeye zorlamak, kullanıcının cevabı doğru yorumlaması (özellikle kritik uygulamalarda) için atılacak en önemli adımdır.